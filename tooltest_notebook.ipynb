{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # There are going to be some things we want to initialize lazily to economize on resources and reuse constructor calls.\n",
    "import torch\n",
    "# everything will use the same tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "mistral = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mistral, padding_side = \"right\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267_477_061\n",
      "Max length: 236695, estimated tokens: 87_664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a794519d622141bbbc85cbfc43de2ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/217608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fe70d29df443b4b7fb0086372ccab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Everything will use the same dataset and dataloaders\n",
    "repo = \"wikimedia/wikipedia\"\n",
    "import datasets\n",
    "ds = datasets.load_dataset(repo, \"20231101.simple\")\n",
    "def quick_estimate_tokens(ds, field=\"text\", chars_per_token=2.7):\n",
    "    tally = 0\n",
    "    max_len = 0\n",
    "    lengths = {}\n",
    "    for row in ds:\n",
    "        l = len(row[field])\n",
    "        tally += l\n",
    "        lengths[l] = lengths.get(l, 0) + 1\n",
    "        if l > max_len:\n",
    "            max_len = l\n",
    "\n",
    "    print(f'{int(tally):_}')\n",
    "    print(f'Max length: {max_len}, estimated tokens: {int(max_len / chars_per_token):_}')\n",
    "    lengths = list(lengths.items())\n",
    "    lengths.sort(reverse=True)\n",
    "    return int(tally/chars_per_token), lengths\n",
    "\n",
    "total, length = quick_estimate_tokens(ds['train'], field=\"text\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "max_tokens = 512\n",
    "def batch_tokenize(batch):\n",
    "    return {\"input_ids\": tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=max_tokens).input_ids}\n",
    "\n",
    "tokenized = ds.map(batch_tokenize, batched=True, batch_size=1000)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized.set_format(type='torch', columns=['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "note: tying weights\n",
      "note: tying weights\n",
      "Base / test model:\n",
      "10_554_880 / 10_554_880 parameters;\n",
      "2_362_880 / 2_362_880 without embeddings.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(tokenized[\"train\"], batch_size=batch_size, shuffle = True)\n",
    "eval_loader = DataLoader(tokenized[\"test\"], batch_size=32, shuffle = False)\n",
    "\n",
    "\n",
    "import sys\n",
    "path = r'C:\\Users\\infin\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling'\n",
    "sys.path.insert(0, path)\n",
    "from mixers import MixerModel, EmbeddingVectorizer, EmbeddingAndPositionalVectorizer, AttentionMixer, GatedStateMixer, no_activation, LinearAttentionMixer\n",
    "import torch\n",
    "from functools import partial\n",
    "model_dim, layers, heads = 256, 3, 4\n",
    "max_seq_len = 512 ## !!! Should we factor this out of being a required argument?  Or is it, even, now?\n",
    "\n",
    "base_model = MixerModel(\n",
    "    model_size = model_dim,\n",
    "    num_layers = layers,\n",
    "    max_seq_len = 512, \n",
    "    vectorizer = EmbeddingVectorizer,\n",
    "    seq_mixer = (AttentionMixer, {\"num_heads\": heads, \"apply_rope\": True}),\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "test_model = MixerModel(\n",
    "    model_size = model_dim,\n",
    "    num_layers = layers,\n",
    "    max_seq_len = 512,\n",
    "    vectorizer = EmbeddingVectorizer,\n",
    "    seq_mixer = (LinearAttentionMixer, {\"num_heads\": heads, \"apply_rope\": True, \"feature_map\": LinearAttentionMixer.taylor_expansion}),\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "print(\n",
    "f\"\"\"Base / test model:\n",
    "{base_model.num_parameters():_} / {test_model.num_parameters():_} parameters;\n",
    "{base_model.num_parameters(include_embeddings = False):_} / {test_model.num_parameters(include_embeddings=False):_} without embeddings.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epochs starting from epoch 1; 6801 steps per epoch.\n",
      "Beginning epoch 1\n",
      "{'mode': 'train', 'epoch': 1, 'step': 250, 'steps': 250, 'seconds': 19.169811964035034, 'total_seconds': 19.169811964035034, 'loss': 8.573249092102051, 'ppl': 5288.28271484375}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 500, 'steps': 250, 'seconds': 18.491865634918213, 'total_seconds': 37.66167759895325, 'loss': 5.82037721824646, 'ppl': 337.0992431640625}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 750, 'steps': 250, 'seconds': 18.40096664428711, 'total_seconds': 56.062644243240356, 'loss': 4.985503973007202, 'ppl': 146.2772979736328}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1000, 'steps': 250, 'seconds': 18.44843029975891, 'total_seconds': 74.51107454299927, 'loss': 4.5791409282684326, 'ppl': 97.43067932128906}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1250, 'steps': 250, 'seconds': 18.46306300163269, 'total_seconds': 92.97413754463196, 'loss': 4.288870355606079, 'ppl': 72.88408660888672}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1500, 'steps': 250, 'seconds': 18.71122455596924, 'total_seconds': 111.6853621006012, 'loss': 4.053894397735596, 'ppl': 57.621429443359375}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1750, 'steps': 250, 'seconds': 18.59215784072876, 'total_seconds': 130.27751994132996, 'loss': 3.892636203765869, 'ppl': 49.040000915527344}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2000, 'steps': 250, 'seconds': 18.711390018463135, 'total_seconds': 148.9889099597931, 'loss': 3.75871484375, 'ppl': 42.89326858520508}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2250, 'steps': 250, 'seconds': 18.67581081390381, 'total_seconds': 167.6647207736969, 'loss': 3.66392649269104, 'ppl': 39.01423645019531}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2500, 'steps': 250, 'seconds': 18.544442415237427, 'total_seconds': 186.20916318893433, 'loss': 3.491432012557983, 'ppl': 32.83292770385742}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2750, 'steps': 250, 'seconds': 18.592145442962646, 'total_seconds': 204.80130863189697, 'loss': 3.3861821489334107, 'ppl': 29.552906036376953}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3000, 'steps': 250, 'seconds': 18.481038570404053, 'total_seconds': 223.28234720230103, 'loss': 3.298990273475647, 'ppl': 27.085275650024414}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3250, 'steps': 250, 'seconds': 18.554989099502563, 'total_seconds': 241.8373363018036, 'loss': 3.233923065185547, 'ppl': 25.3790225982666}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3500, 'steps': 250, 'seconds': 18.65485644340515, 'total_seconds': 260.49219274520874, 'loss': 3.202908441543579, 'ppl': 24.603986740112305}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3750, 'steps': 250, 'seconds': 18.66252613067627, 'total_seconds': 279.154718875885, 'loss': 3.171776984214783, 'ppl': 23.849828720092773}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4000, 'steps': 250, 'seconds': 18.64515495300293, 'total_seconds': 297.79987382888794, 'loss': 3.164940877914429, 'ppl': 23.687341690063477}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4250, 'steps': 250, 'seconds': 18.65324592590332, 'total_seconds': 316.45311975479126, 'loss': 3.0886886358261108, 'ppl': 21.94827651977539}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4500, 'steps': 250, 'seconds': 18.717714309692383, 'total_seconds': 335.17083406448364, 'loss': 3.084841923713684, 'ppl': 21.864011764526367}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4750, 'steps': 250, 'seconds': 18.796419858932495, 'total_seconds': 353.96725392341614, 'loss': 3.053240846633911, 'ppl': 21.18388557434082}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5000, 'steps': 250, 'seconds': 18.581185579299927, 'total_seconds': 372.54843950271606, 'loss': 3.0395046997070314, 'ppl': 20.894893646240234}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5250, 'steps': 250, 'seconds': 18.696590423583984, 'total_seconds': 391.24502992630005, 'loss': 3.0279083166122436, 'ppl': 20.65398597717285}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5500, 'steps': 250, 'seconds': 18.47317862510681, 'total_seconds': 409.71820855140686, 'loss': 3.0060821352005003, 'ppl': 20.208070755004883}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5750, 'steps': 250, 'seconds': 18.61843252182007, 'total_seconds': 428.33664107322693, 'loss': 2.980703456878662, 'ppl': 19.701669692993164}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6000, 'steps': 250, 'seconds': 18.538945198059082, 'total_seconds': 446.875586271286, 'loss': 2.9859089241027834, 'ppl': 19.80449676513672}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6250, 'steps': 250, 'seconds': 18.658499240875244, 'total_seconds': 465.53408551216125, 'loss': 2.959749538421631, 'ppl': 19.293136596679688}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6500, 'steps': 250, 'seconds': 18.553553819656372, 'total_seconds': 484.0876393318176, 'loss': 2.954447720527649, 'ppl': 19.19112205505371}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6750, 'steps': 250, 'seconds': 18.576980113983154, 'total_seconds': 502.6646194458008, 'loss': 2.9710936698913573, 'ppl': 19.513248443603516}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6801, 'steps': 51, 'seconds': 3.7818119525909424, 'total_seconds': 506.4464313983917, 'loss': 2.91782779787101, 'ppl': 18.501056671142578}\n",
      "{'mode': 'eval', 'epoch': 1, 'step': 756, 'steps': 756, 'seconds': 28.797224044799805, 'total_seconds': 535.2436554431915, 'loss': 2.9310546403839473, 'ppl': 18.747390747070312}\n",
      "Beginning epoch 2\n",
      "{'mode': 'train', 'epoch': 2, 'step': 250, 'steps': 250, 'seconds': 18.653086185455322, 'total_seconds': 553.8967416286469, 'loss': 2.8845962285995483, 'ppl': 17.89634132385254}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 500, 'steps': 250, 'seconds': 18.94822382926941, 'total_seconds': 572.8449654579163, 'loss': 2.8707340450286867, 'ppl': 17.649967193603516}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 750, 'steps': 250, 'seconds': 18.555418729782104, 'total_seconds': 591.4003841876984, 'loss': 2.8655075521469118, 'ppl': 17.557964324951172}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 1000, 'steps': 250, 'seconds': 19.357316970825195, 'total_seconds': 610.7577011585236, 'loss': 2.8568442907333376, 'ppl': 17.406509399414062}\n",
      "training ended by early stopping callback\n",
      "running cleanup routines\n"
     ]
    }
   ],
   "source": [
    "from train import Trainer, SimpleTestCallback, ResidualGatingWarmupCallback, get_warmup_schedule, TimedStoppingCallback, PerplexityStoppingCallback\n",
    "base_trainer = Trainer(\n",
    "    base_model,\n",
    "    train_loader,\n",
    "    eval_loader = eval_loader,\n",
    "    device = \"cuda\",\n",
    "    tokenizer = tokenizer,\n",
    "    log_every = 250,\n",
    "    eval_every = 10_000,\n",
    "    schedule = get_warmup_schedule(),\n",
    "    autocast_dtype = torch.bfloat16,\n",
    "    callbacks = [TimedStoppingCallback(600)]\n",
    ")\n",
    "base_trainer.train(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epochs starting from epoch 1; 6801 steps per epoch.\n",
      "Beginning epoch 1\n",
      "running cleanup routines\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer, SimpleTestCallback, ResidualGatingWarmupCallback, get_warmup_schedule, TimedStoppingCallback, PerplexityStoppingCallback\n\u001b[0;32m      2\u001b[0m test_trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      3\u001b[0m     test_model,\n\u001b[0;32m      4\u001b[0m     train_loader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [TimedStoppingCallback(\u001b[38;5;241m600\u001b[39m)]\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtest_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\train.py:458\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m split_batch:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_dtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32, device_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_dtype):\n\u001b[1;32m--> 458\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_loss(split, output, pad_token_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[0;32m    460\u001b[0m         loss_item \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# this seems like the safest way to do it\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\train.py:21\u001b[0m, in \u001b[0;36mdefault_forward_batch\u001b[1;34m(model, batch)\u001b[0m\n\u001b[0;32m     19\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m unpack_batch(batch)\n\u001b[0;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m---> 21\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[1;32mc:\\Users\\infin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:809\u001b[0m, in \u001b[0;36mMixerModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    807\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer(x)\n\u001b[0;32m    808\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_norm(x)\n\u001b[1;32m--> 809\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm(x)\n\u001b[0;32m    811\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n",
      "File \u001b[1;32mc:\\Users\\infin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:646\u001b[0m, in \u001b[0;36mDecoderBackbone.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 646\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\infin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:547\u001b[0m, in \u001b[0;36mLayerBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 547\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\infin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:561\u001b[0m, in \u001b[0;36mPreNormResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    559\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_order:\n\u001b[1;32m--> 561\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m residual\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\infin\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:326\u001b[0m, in \u001b[0;36mLinearAttentionMixer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    324\u001b[0m     keys \u001b[38;5;241m=\u001b[39m RoPE\u001b[38;5;241m.\u001b[39membed(keys, head_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# apply feature maps\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_map(keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# compute linear attention\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:308\u001b[0m, in \u001b[0;36mLinearAttentionMixer.taylor_expansion\u001b[1;34m(cls, x, head_dim)\u001b[0m\n\u001b[0;32m    306\u001b[0m device \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m    307\u001b[0m _1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(x[:,:,:,:\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 308\u001b[0m _x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_sqrt(\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m,device)\n\u001b[0;32m    309\u001b[0m _x2 \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_sqrt(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mhead_dim, device)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([_1, _x, _x2], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\aimodels\\projects\\tooling\\mixers.py:301\u001b[0m, in \u001b[0;36mLinearAttentionMixer._cached_sqrt\u001b[1;34m(cls, x, device)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_sqrts:\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_sqrts[x] \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(x)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_sqrts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from train import Trainer, SimpleTestCallback, ResidualGatingWarmupCallback, get_warmup_schedule, TimedStoppingCallback, PerplexityStoppingCallback\n",
    "test_trainer = Trainer(\n",
    "    test_model,\n",
    "    train_loader,\n",
    "    eval_loader = eval_loader,\n",
    "    device = \"cuda\",\n",
    "    tokenizer = tokenizer,\n",
    "    log_every = 250,\n",
    "    eval_every = 10_000,\n",
    "    schedule = get_warmup_schedule(),\n",
    "    autocast_dtype = torch.bfloat16,\n",
    "    callbacks = [TimedStoppingCallback(600)]\n",
    ")\n",
    "test_trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "b = pd.DataFrame(base_trainer.logger.log)\n",
    "b[\"model\"] = \"base\"\n",
    "t = pd.DataFrame(test_trainer.logger.log)\n",
    "t[\"model\"] = \"test\"\n",
    "logs_df = pd.concat([b, t])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# a plot with two lines...one is where model = gelu, mode = train, steps = 250; the other is the same but with model = swiglu\n",
    "train = logs_df[logs_df[\"mode\"] == \"train\"]\n",
    "full_steps = train[train[\"steps\"] == 250]\n",
    "full_steps = full_steps[full_steps[\"total_seconds\"] >=300]\n",
    "b = full_steps[full_steps[\"model\"] == \"base\"]\n",
    "t = full_steps[full_steps[\"model\"] == \"test\"]\n",
    "# plot ppl vs total_seconds\n",
    "# clear the plot\n",
    "plt.clf()\n",
    "plt.plot(b[\"total_seconds\"], b[\"ppl\"], label=\"base\")\n",
    "plt.plot(t[\"total_seconds\"], t[\"ppl\"], label=\"test\")\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
