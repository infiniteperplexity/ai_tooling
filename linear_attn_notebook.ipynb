{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial # There are going to be some things we want to initialize lazily to economize on resources and reuse constructor calls.\n",
    "import torch\n",
    "# everything will use the same tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "mistral = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mistral, padding_side = \"right\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267_477_061\n",
      "Max length: 236695, estimated tokens: 87_664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9a8065ed6c4f4298b86159ab380d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/217608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c50e588c754d0eb1b42c2e5689a63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24179 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Everything will use the same dataset and dataloaders\n",
    "repo = \"wikimedia/wikipedia\"\n",
    "import datasets\n",
    "ds = datasets.load_dataset(repo, \"20231101.simple\")\n",
    "def quick_estimate_tokens(ds, field=\"text\", chars_per_token=2.7):\n",
    "    tally = 0\n",
    "    max_len = 0\n",
    "    lengths = {}\n",
    "    for row in ds:\n",
    "        l = len(row[field])\n",
    "        tally += l\n",
    "        lengths[l] = lengths.get(l, 0) + 1\n",
    "        if l > max_len:\n",
    "            max_len = l\n",
    "\n",
    "    print(f'{int(tally):_}')\n",
    "    print(f'Max length: {max_len}, estimated tokens: {int(max_len / chars_per_token):_}')\n",
    "    lengths = list(lengths.items())\n",
    "    lengths.sort(reverse=True)\n",
    "    return int(tally/chars_per_token), lengths\n",
    "\n",
    "total, length = quick_estimate_tokens(ds['train'], field=\"text\")\n",
    "ds = ds[\"train\"].train_test_split(test_size=0.1)\n",
    "\n",
    "max_tokens = 512\n",
    "def batch_tokenize(batch):\n",
    "    return {\"input_ids\": tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=max_tokens).input_ids}\n",
    "\n",
    "tokenized = ds.map(batch_tokenize, batched=True, batch_size=1000)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized.set_format(type='torch', columns=['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(tokenized[\"train\"], batch_size=batch_size, shuffle = True)\n",
    "eval_loader = DataLoader(tokenized[\"test\"], batch_size=32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Failed to import the causal dot product kernel... \n",
      "note: tying weights\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from zoology_mixers.based import Based\n",
    "\n",
    "from mixers import MixerModel, EmbeddingVectorizer, EmbeddingAndPositionalVectorizer, AttentionMixer, GatedStateMixer, no_activation, LinearAttentionMixer\n",
    "import torch\n",
    "from functools import partial\n",
    "model_dim, layers, heads = 256, 3, 4\n",
    "max_seq_len = 512 ## !!! Should we factor this out of being a required argument?  Or is it, even, now?\n",
    "\n",
    "test_model = MixerModel(\n",
    "    model_size = model_dim,\n",
    "    num_layers = layers,\n",
    "    max_seq_len = 512,\n",
    "    vectorizer = EmbeddingVectorizer,\n",
    "    #seq_mixer = (LinearAttentionMixer, {\"num_heads\": heads, \"apply_rope\": True, \"feature_map\": LinearAttentionMixer.taylor_expansion}),\n",
    "    seq_mixer = (LinearAttentionMixer, {\"num_heads\": heads, \"apply_rope\": True, \"feature_map\": LinearAttentionMixer.relu}),\n",
    "    #seq_mixer = (Based, {\"num_key_value_heads\": heads, \"feature_dim\": model_dim // heads, \"num_heads\": heads, \"feature_name\": \"taylor_exp\", \"apply_rotary\": True, \"train_view\": \"quadratic\"}), # This is their revised version\n",
    "    #seq_mixer = (Based, {\"num_key_value_heads\": heads, \"feature_dim\": model_dim // heads, \"num_heads\": heads, \"feature_name\": \"taylor_exp\"}), Based from based.py also runs out of memory\n",
    "    #seq_mixer = LinAttnWrapper, # also runs out of memory\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2 epochs starting from epoch 1; 6801 steps per epoch.\n",
      "Beginning epoch 1\n",
      "{'mode': 'train', 'epoch': 1, 'step': 250, 'steps': 250, 'seconds': 131.8725323677063, 'total_seconds': 131.8725323677063, 'loss': 4.569998227968812, 'ppl': 96.5439453125}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 500, 'steps': 250, 'seconds': 130.15543961524963, 'total_seconds': 262.02797198295593, 'loss': 4.411649387985468, 'ppl': 82.40525817871094}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 750, 'steps': 250, 'seconds': 130.3861813545227, 'total_seconds': 392.41415333747864, 'loss': 4.229723438613116, 'ppl': 68.69823455810547}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1000, 'steps': 250, 'seconds': 129.63615489006042, 'total_seconds': 522.0503082275391, 'loss': 4.067895561374724, 'ppl': 58.43385314941406}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1250, 'steps': 250, 'seconds': 131.967280626297, 'total_seconds': 654.0175888538361, 'loss': 3.8627132078930737, 'ppl': 47.594303131103516}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1500, 'steps': 250, 'seconds': 129.10446190834045, 'total_seconds': 783.1220507621765, 'loss': 3.7300297502428292, 'ppl': 41.68035125732422}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 1750, 'steps': 250, 'seconds': 126.98646759986877, 'total_seconds': 910.1085183620453, 'loss': 3.624355362929404, 'ppl': 37.50053787231445}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2000, 'steps': 250, 'seconds': 128.49382209777832, 'total_seconds': 1038.6023404598236, 'loss': 3.5301806927658617, 'ppl': 34.13013458251953}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2250, 'steps': 250, 'seconds': 127.81702518463135, 'total_seconds': 1166.419365644455, 'loss': 3.473065885953605, 'ppl': 32.23542022705078}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2500, 'steps': 250, 'seconds': 125.52901124954224, 'total_seconds': 1291.9483768939972, 'loss': 3.393324295450002, 'ppl': 29.764738082885742}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 2750, 'steps': 250, 'seconds': 125.9293475151062, 'total_seconds': 1417.8777244091034, 'loss': 3.3493658941835167, 'ppl': 28.48466682434082}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3000, 'steps': 250, 'seconds': 125.6423692703247, 'total_seconds': 1543.520093679428, 'loss': 3.2883897591643034, 'ppl': 26.799673080444336}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3250, 'steps': 250, 'seconds': 125.18863153457642, 'total_seconds': 1668.7087252140045, 'loss': 3.251724630959332, 'ppl': 25.83485984802246}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3500, 'steps': 250, 'seconds': 126.00213146209717, 'total_seconds': 1794.7108566761017, 'loss': 3.219933348443359, 'ppl': 25.026451110839844}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 3750, 'steps': 250, 'seconds': 124.17039656639099, 'total_seconds': 1918.8812532424927, 'loss': 3.184945757418871, 'ppl': 24.165979385375977}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4000, 'steps': 250, 'seconds': 123.7355523109436, 'total_seconds': 2042.6168055534363, 'loss': 3.1369691704139115, 'ppl': 23.033946990966797}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4250, 'steps': 250, 'seconds': 129.16911935806274, 'total_seconds': 2171.785924911499, 'loss': 3.13115067197755, 'ppl': 22.90031623840332}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4500, 'steps': 250, 'seconds': 128.34557723999023, 'total_seconds': 2300.1315021514893, 'loss': 3.0920356668792666, 'ppl': 22.02186393737793}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 4750, 'steps': 250, 'seconds': 130.259907245636, 'total_seconds': 2430.3914093971252, 'loss': 3.0560830018632115, 'ppl': 21.24418067932129}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5000, 'steps': 250, 'seconds': 129.8248996734619, 'total_seconds': 2560.216309070587, 'loss': 3.0657283604964616, 'ppl': 21.45008087158203}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5250, 'steps': 250, 'seconds': 129.44589471817017, 'total_seconds': 2689.6622037887573, 'loss': 3.0600274777039886, 'ppl': 21.328140258789062}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5500, 'steps': 250, 'seconds': 126.13709592819214, 'total_seconds': 2815.7992997169495, 'loss': 3.0123705349080265, 'ppl': 20.33555030822754}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 5750, 'steps': 250, 'seconds': 126.01832437515259, 'total_seconds': 2941.817624092102, 'loss': 3.001377023935318, 'ppl': 20.113216400146484}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6000, 'steps': 250, 'seconds': 125.04506850242615, 'total_seconds': 3066.862692594528, 'loss': 2.9637563767917454, 'ppl': 19.37059783935547}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6250, 'steps': 250, 'seconds': 125.42169523239136, 'total_seconds': 3192.2843878269196, 'loss': 2.9307697021514176, 'ppl': 18.742050170898438}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6500, 'steps': 250, 'seconds': 125.31945276260376, 'total_seconds': 3317.6038405895233, 'loss': 2.9486075037904085, 'ppl': 19.07936668395996}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6750, 'steps': 250, 'seconds': 125.15417432785034, 'total_seconds': 3442.7580149173737, 'loss': 2.9428017552755774, 'ppl': 18.968917846679688}\n",
      "{'mode': 'train', 'epoch': 1, 'step': 6801, 'steps': 51, 'seconds': 25.219848155975342, 'total_seconds': 3467.977863073349, 'loss': 2.9737252672365058, 'ppl': 19.564668655395508}\n",
      "{'mode': 'eval', 'epoch': 1, 'step': 756, 'steps': 756, 'seconds': 52.18852090835571, 'total_seconds': 3520.1663839817047, 'loss': 3.441712719738168, 'ppl': 31.240415573120117}\n",
      "Beginning epoch 2\n",
      "{'mode': 'train', 'epoch': 2, 'step': 250, 'steps': 250, 'seconds': 125.14245820045471, 'total_seconds': 3645.3088421821594, 'loss': 2.8253879384100435, 'ppl': 16.86748695373535}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 500, 'steps': 250, 'seconds': 126.44966530799866, 'total_seconds': 3771.758507490158, 'loss': 2.86417591188848, 'ppl': 17.534595489501953}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 750, 'steps': 250, 'seconds': 124.65779328346252, 'total_seconds': 3896.4163007736206, 'loss': 2.837383618414402, 'ppl': 17.071041107177734}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 1000, 'steps': 250, 'seconds': 124.10330438613892, 'total_seconds': 4020.5196051597595, 'loss': 2.8286849149614572, 'ppl': 16.923189163208008}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 1250, 'steps': 250, 'seconds': 126.31497025489807, 'total_seconds': 4146.834575414658, 'loss': 2.826081221759319, 'ppl': 16.879186630249023}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 1500, 'steps': 250, 'seconds': 122.60701727867126, 'total_seconds': 4269.441592693329, 'loss': 2.831640993196517, 'ppl': 16.973291397094727}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 1750, 'steps': 250, 'seconds': 122.28667616844177, 'total_seconds': 4391.728268861771, 'loss': 2.8278337569087744, 'ppl': 16.908790588378906}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 2000, 'steps': 250, 'seconds': 124.8993763923645, 'total_seconds': 4516.627645254135, 'loss': 2.800393755823374, 'ppl': 16.45112419128418}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 2250, 'steps': 250, 'seconds': 122.48281025886536, 'total_seconds': 4639.1104555130005, 'loss': 2.7914885276295243, 'ppl': 16.30527114868164}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 2500, 'steps': 250, 'seconds': 122.45474529266357, 'total_seconds': 4761.565200805664, 'loss': 2.8037631063126027, 'ppl': 16.50664710998535}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 2750, 'steps': 250, 'seconds': 124.5277693271637, 'total_seconds': 4886.092970132828, 'loss': 2.807835248209536, 'ppl': 16.574003219604492}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 3000, 'steps': 250, 'seconds': 123.0235185623169, 'total_seconds': 5009.116488695145, 'loss': 2.7859947035051884, 'ppl': 16.215940475463867}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 3250, 'steps': 250, 'seconds': 122.71213030815125, 'total_seconds': 5131.828619003296, 'loss': 2.7831221642978488, 'ppl': 16.169424057006836}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 3500, 'steps': 250, 'seconds': 123.76874661445618, 'total_seconds': 5255.597365617752, 'loss': 2.7742990833707153, 'ppl': 16.027389526367188}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 3750, 'steps': 250, 'seconds': 123.78325629234314, 'total_seconds': 5379.380621910095, 'loss': 2.7708668436333537, 'ppl': 15.972474098205566}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 4000, 'steps': 250, 'seconds': 123.38580441474915, 'total_seconds': 5502.766426324844, 'loss': 2.771436176083982, 'ppl': 15.98157024383545}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 4250, 'steps': 250, 'seconds': 124.18657732009888, 'total_seconds': 5626.953003644943, 'loss': 2.7364600327312947, 'ppl': 15.432257652282715}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 4500, 'steps': 250, 'seconds': 124.27400231361389, 'total_seconds': 5751.227005958557, 'loss': 2.7332786582894624, 'ppl': 15.3832426071167}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 4750, 'steps': 250, 'seconds': 122.1689841747284, 'total_seconds': 5873.3959901332855, 'loss': 2.748779546380043, 'ppl': 15.623552322387695}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 5000, 'steps': 250, 'seconds': 122.70129156112671, 'total_seconds': 5996.097281694412, 'loss': 2.719499637275934, 'ppl': 15.172727584838867}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 5250, 'steps': 250, 'seconds': 122.77436375617981, 'total_seconds': 6118.871645450592, 'loss': 2.7466734857074915, 'ppl': 15.59068489074707}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 5500, 'steps': 250, 'seconds': 122.98647093772888, 'total_seconds': 6241.858116388321, 'loss': 2.716361753463745, 'ppl': 15.125192642211914}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 5750, 'steps': 250, 'seconds': 124.37636971473694, 'total_seconds': 6366.234486103058, 'loss': 2.7569822753071787, 'ppl': 15.752236366271973}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 6000, 'steps': 250, 'seconds': 124.2185845375061, 'total_seconds': 6490.453070640564, 'loss': 2.710473847506568, 'ppl': 15.036397933959961}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 6250, 'steps': 250, 'seconds': 123.13695764541626, 'total_seconds': 6613.59002828598, 'loss': 2.73309790173918, 'ppl': 15.38045883178711}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 6500, 'steps': 250, 'seconds': 124.43704795837402, 'total_seconds': 6738.027076244354, 'loss': 2.72497895424068, 'ppl': 15.256092071533203}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 6750, 'steps': 250, 'seconds': 123.80646538734436, 'total_seconds': 6861.833541631699, 'loss': 2.7113691700994966, 'ppl': 15.0498685836792}\n",
      "{'mode': 'train', 'epoch': 2, 'step': 6801, 'steps': 51, 'seconds': 25.128498792648315, 'total_seconds': 6886.962040424347, 'loss': 2.6601725799675604, 'ppl': 14.298754692077637}\n",
      "{'mode': 'eval', 'epoch': 2, 'step': 756, 'steps': 756, 'seconds': 51.99250411987305, 'total_seconds': 6938.95454454422, 'loss': 3.2334553110536444, 'ppl': 25.36716079711914}\n",
      "running cleanup routines\n"
     ]
    }
   ],
   "source": [
    "from train import Trainer, SimpleTestCallback, ResidualGatingWarmupCallback, get_warmup_schedule, TimedStoppingCallback, PerplexityStoppingCallback\n",
    "test_trainer = Trainer(\n",
    "    test_model,\n",
    "    train_loader,\n",
    "    eval_loader = eval_loader,\n",
    "    device = \"cuda\",\n",
    "    tokenizer = tokenizer,\n",
    "    log_every = 250,\n",
    "    eval_every = 10_000,\n",
    "    schedule = get_warmup_schedule(),\n",
    "    autocast_dtype = torch.bfloat16,\n",
    "    gradient_accumulation_batch_size = 1,\n",
    "    #callbacks = [TimedStoppingCallback(600)]\n",
    ")\n",
    "test_trainer.train(2)\n",
    "# It explodes during the cumsum step...is this a memory-intensive step?  That would explain why they had a draft of an alternate implementation.\n",
    "# Wait is this new? https://github.com/HazyResearch/zoology/blob/main/zoology/mixers/based.py\n",
    "# Yeah this looks like it has been refactored from top to bottom.  So...archive the older stuff?\n",
    "# Wow the quadratic view is abysmally slow.\n",
    "# Okay so the relu version here looks like it's going to have decent performance per epoch, but it's going slow.  So it might need the fast implementation; unfortunately it took like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.666666666666664"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3520/60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
